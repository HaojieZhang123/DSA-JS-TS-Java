# Big O Notation

Big O is a way to categorize an algorithm's time or memory requirements based on input size. It is not an exact measurement—it does not tell you how many CPU cycles an algorithm takes, but generalizes the growth of your algorithm as input increases.


## What is Big O Notation?

Big O notation is a mathematical tool to describe the upper bound of an algorithm's time or space complexity as a function of input size $n$. It provides a high-level understanding of how an algorithm's performance scales as the input grows, allowing for comparison between different algorithms based on efficiency.

Put simply: as your input grows, how fast do your computation or memory requirements grow?


**It is not:**
- A measurement of CPU cycles
- A benchmark
- A profile of actual performance

**It is:**
- A mathematical model describing growth rate as input grows
- A tool for reasoning about scalability
- A way to compare algorithms independent of hardware and implementation details


# Formal Definition

**Big O notation** gives an upper bound on growth rate:

> An algorithm is $O(f(n))$ if there exist constants $c > 0$ and $n_0 \ge 0$ such that, for all $n \ge n_0$,
>
> $$
> T(n) \leq c \cdot f(n)
> $$

where:
- $T(n)$ = running time for input size $n$
- $f(n)$ = comparison function (growth rate)
- $c$ = positive constant
- $n_0$ = threshold from which the bound holds


# Why Do We Use It?

We need a way to compare algorithms **without depending** on:
- CPU clock
- Compiler optimizations
- RAM speed
- Programming language overhead
- Implementation details

Big O helps us decide which data structures and algorithms to use by predicting their performance as input grows. Sometimes, an $O(n)$ algorithm in Python can outperform an $O(\log n)$ algorithm in Java for small inputs, but as $n$ grows, the $O(\log n)$ algorithm will eventually win.

> **Important concept 1:**
> - Growth is with respect to the input size $n$.


Memory growth is not computationally free, but in algorithm analysis, we focus on how requirements scale with $n$. In languages like Go or JavaScript, memory can be kept around, causing faster growth and sometimes program pauses for cleanup.


## Example: Linear Time

Consider the following code:

```ts
function sum_char_codes(n: string): number {
    let sum = 0;
    for (let i = 0; i < n.length; ++i) {
        sum += n.charCodeAt(i);
    }

    return sum;
}
```


How does the execution time grow with input?

We have a linear relationship: **$O(n)$ time complexity**.

How can you tell? Simplest trick: **look for loops**: here, we loop for the length of $n$.

Consider the following code:

```ts
function sum_char_codes(n: string): number {
    let sum = 0;
    for (let i = 0; i < n.length; ++i) {
        sum += n.charCodeAt(i);
    }

    for (let i = 0; i < n.length; ++i) {
        sum += n.charCodeAt(i);
    }

    return sum;
}
```


The previous one was $O(n)$. Is this $O(2n)$? No.

> **Important concept 2:**
> 1. Growth is with respect to the input
> 2. **Constants are dropped**

$O(2n) \to O(n)$—Big O describes the upper bound, so constants become irrelevant as $n$ grows.

For example, $O(10n)$ vs $O(n^2)$: the quadratic function grows much faster as $n$ increases, regardless of the constant in front of the linear one.


There are practical vs theoretical differences. Just because $O(n)$ is better than $O(n^2)$ asymptotically, doesn't mean it's always faster for small $n$.

Remember: we drop constants. $O(100n)$ is better than $O(n^2)$ for large $n$, but for small $n$, $O(n^2)$ might be faster.


## Example: Early Return

```ts
function sum_char_codes(n: string): number {
    let sum = 0;
    for (let i = 0; i < n.length; ++i) {
        const charCode = n.charCodeAt(i);
        // E
        if (charCode === 69) {
            return sum;
        }

        sum += charCode;
    }
    return sum;
}
```


In Big O, we often consider the **worst case**. Here, any string with 'E' will terminate early (unless 'E' is last), but it's still $O(n)$.

> **Important concept 3:**
> 1. Growth is with respect to the input
> 2. Constants are dropped
> 3. **Worst case scenario is usually the way we measure**


# Core Concepts

## 1. Growth is with Respect to the Input

Big O always describes how runtime increases as $n$ increases.

What is **not** included:
- Value of elements
- CPU loads
- Memory bandwidth
- Network latency

Only $n$, the input size, matters.

## 2. Constants are Dropped

$O(2n) \to O(n)$

$O(100n) \to O(n)$

$O(n + 10) \to O(n)$

Constants don't change the growth rate as $n$ increases.


## 3. Usually Worst Case Scenario is the Way We Measure

Most conventions use **worst-case** because:
- Easier to reason about
- Guarantees performance no matter the input
- Many data structures (e.g., hash tables) degrade to worse performance in worst-case

Worst case is *usually* the way we measure, but not always.

- **Big O**: worst case
- **Big Omega**: best case
- **Big Theta**: tight bound (average case)


Example: Sequential search in array

```ts
function sequentialSearch(arr: number[], target: number): number {
    for (let i = 0; i < arr.length; ++i) {
        if (arr[i] === target) {
            return i;
        }
    }
    return -1;
}
```
- Worst case: $O(n)$ (target not found or at end)
- Best case: $O(1)$ (target at beginning)
- Average case: $O(n/2)$

For interviews, theta is often more accurate than O, but O is more commonly used in practice.


# Common Growth Classifications


## $O(1)$ — Constant Time

Operation takes the same time regardless of input size.

Examples:
- Accessing array element by index
- Hash map insert/lookup
- Arithmetic operations


## $O(\log n)$ — Logarithmic Time

Operation time grows logarithmically with input size. Each step reduces the problem size by a constant factor.

Examples:
- Binary search in sorted array
- Balanced binary search tree operations (insert, delete, lookup)
- Heap insert/remove
- Divide-and-conquer algorithms (e.g., mergesort, quicksort)

If you can halve the problem size each step, you get logarithmic time.


## $O(n)$ — Linear Time

Operation time grows linearly with input size.

Examples:
- Iterating through array or list
- Simple search in unsorted array
- Finding max element in array
- Copying array


## $O(n \log n)$ — Linearithmic Time

Appears in efficient sorting algorithms.

Examples:
- Mergesort
- Quicksort (average case)
- Heapsort
- Radix sort


## $O(n^2)$ — Quadratic Time

Operation time grows quadratically with input size. Typically arises from nested loops.

Examples:
- Checking all pairs
- Bubble sort
- Insertion sort (worst case)
- Matrix multiplication (naive)


## $O(2^n)$ — Exponential Time

Operation time grows exponentially with input size. Mostly seen in brute-force combinatorial algorithms.

Examples:
- Generating all subsets
- Solving NP-hard problems with backtracking (e.g., traveling salesman)


## $O(n!)$ — Factorial Time

Operation time grows factorially with input size. Worst of the common complexities.

Examples:
- Generating all permutations
- Brute-forcing TSP with all permutations


## $O(\sqrt{n})$ — Square Root Time

Operation time grows with the square root of input size. Less common but appears in some algorithms.

Examples:
- Prime number checking (trial division up to $\sqrt{n}$)
- Some 2-pointer problems
- Checking divisibility
- Jump search


# How to Determine Big O in Practice

## 1. Look for Loops
- One loop over $n$ $\to O(n)$
- Nested loops $\to$ multiply exponents: $O(n^2)$, $O(n^3)$

## 2. Look for Division/Halving
- $n = n / 2$ each iteration $\to O(\log n)$

## 3. Add Separate Blocks
```ts
O(n) + O(\log n) \to O(n)
O(n) + O(n^2) \to O(n^2)
```

## 4. Drop Constants
```ts
O(2n) \to O(n)
O(100n) \to O(n)
O(n + 10) \to O(n)
```

## 5. Focus on Worst Case (Usually)
Consider the input that causes the maximum number of operations.

Especially for:
- Early returns
- Break statements
- Hash collisions

You generally assume the scenario that forces the most work.


# Amortized Analysis

Some operations may be expensive occasionally but cheap on average over many operations.

Amortized analysis is a way to reason about the average behavior of an algorithm.

Average cost per operation is used $\to$ amortized analysis.

Examples:
- Dynamic array resizing (append operation)
```ts
append(item):
    if size == capacity:
        resize array to double capacity
    add item
```
- Hash table resizing (insert operation)
```ts
insert(key, value):
    if load factor > threshold:
        resize table to double capacity
    add key-value pair
```
- Stack push/pop with occasional resizing
```ts
push(item):
    if size == capacity:
        resize array to double capacity
    add item
pop():
    remove item
    if size < capacity / 4:
        resize array to half capacity
```

Even though resizing is $O(n)$, it happens infrequently enough that the amortized cost remains $O(1)$.


# Real-World Performance Considerations

Big O provides a high-level understanding of algorithm efficiency, but real-world performance can be influenced by factors not captured by Big O notation:
- Cache locality (whether data is close to CPU)
- Memory fragmentation
- JavaScript/Go/Java garbage collection pauses
- CPU branch prediction
- Interpreter vs compiled language overhead
- Bytecode vs native compilation
- Constant factors hidden by Big O notation
- Real data distribution and input characteristics

Example:
An $O(n)$ algorithm with cache misses may perform worse than an $O(n \log n)$ algorithm with sequential memory access for practical input sizes.


# Misconceptions about Big O

## $O(1)$ Means Fast
Not necessarily. True asymptotically, but hash collisions, large constants, or disk access can make $O(1)$ operations slow in practice.

## Two Loops Always Means $O(n^2)$
Only if loops are nested. Sequential loops are additive, not multiplicative:
$O(n + n) = O(2n) = O(n)$

## Worst Case is Always What Matters
Not always. Average case or best case may be more relevant depending on context.

## Big O Describes Exact Performance
Big O describes growth rate, not exact timings. Two $O(n)$ algorithms can have vastly different constants and real-world performance.


# Summary

Big O notation is a powerful tool for analyzing algorithm efficiency by describing how time or space requirements grow with input size. It abstracts away implementation details and focuses on scalability. However, real-world performance can be influenced by factors beyond Big O, so it's important to consider practical implications alongside theoretical analysis.

